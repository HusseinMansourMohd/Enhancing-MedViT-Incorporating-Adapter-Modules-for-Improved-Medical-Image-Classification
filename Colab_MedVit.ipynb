{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSMvVCPgoy-u",
        "outputId": "28074d24-e7b5-4739-fa7e-1da0ffe846e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Jul 23 01:48:21 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB30odbcpGbd",
        "outputId": "8f002b85-d2db-4d3b-e52d-360018dcc8ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification'...\n",
            "remote: Enumerating objects: 324, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 324 (delta 9), reused 15 (delta 6), pack-reused 306\u001b[K\n",
            "Receiving objects: 100% (324/324), 101.80 KiB | 4.24 MiB/s, done.\n",
            "Resolving deltas: 100% (178/178), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/HusseinMansourMohd/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "P2rvu9MLpGeC"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.utils\n",
        "import torchvision.datasets as dsets\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZlEbA5GpGhZ",
        "outputId": "f105d317-f277-415b-c07e-dbb371d3b56c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 timm-0.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBuxJl_gCJQR",
        "outputId": "64a08a49-6b69-48b0-a9db-c1a0335d93cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting einops==0.6.1\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install einops==0.6.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqN4jdJspGkN",
        "outputId": "b385d731-f9e9-4b3c-b3c8-bc879a0955b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification\n"
          ]
        }
      ],
      "source": [
        "cd /content/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4FycXE9t-Vb",
        "outputId": "f1171116-c41c-449c-e1c7-683924762265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Deformable-DETR'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Counting objects: 100% (124/124), done.\u001b[K\n",
            "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "remote: Total 124 (delta 42), reused 84 (delta 36), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (124/124), 5.67 MiB | 17.22 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/HusseinMansourMohd/Deformable-DETR.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn0qoGdYuCLi",
        "outputId": "5c6875d5-d6bf-468d-d7ac-86d62674c2aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification/Deformable-DETR\n"
          ]
        }
      ],
      "source": [
        "%cd Deformable-DETR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1KoKJ4rt_YY",
        "outputId": "b7f4f0c5-2ad2-409e-95e3-b2fd18d9547a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing MultiScaleDeformableAttention.egg-info/PKG-INFO\n",
            "writing dependency_links to MultiScaleDeformableAttention.egg-info/dependency_links.txt\n",
            "writing top-level names to MultiScaleDeformableAttention.egg-info/top_level.txt\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
            "writing manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:398: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 11.8\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/modules\n",
            "copying build/lib.linux-x86_64-cpython-310/modules/__init__.py -> build/bdist.linux-x86_64/egg/modules\n",
            "copying build/lib.linux-x86_64-cpython-310/modules/ms_deform_attn.py -> build/bdist.linux-x86_64/egg/modules\n",
            "creating build/bdist.linux-x86_64/egg/functions\n",
            "copying build/lib.linux-x86_64-cpython-310/functions/__init__.py -> build/bdist.linux-x86_64/egg/functions\n",
            "copying build/lib.linux-x86_64-cpython-310/functions/ms_deform_attn_func.py -> build/bdist.linux-x86_64/egg/functions\n",
            "copying build/lib.linux-x86_64-cpython-310/MultiScaleDeformableAttention.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "byte-compiling build/bdist.linux-x86_64/egg/modules/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/modules/ms_deform_attn.py to ms_deform_attn.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/functions/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/functions/ms_deform_attn_func.py to ms_deform_attn_func.cpython-310.pyc\n",
            "creating stub loader for MultiScaleDeformableAttention.cpython-310-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/MultiScaleDeformableAttention.py to MultiScaleDeformableAttention.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.MultiScaleDeformableAttention.cpython-310: module references __file__\n",
            "creating 'dist/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.10/dist-packages/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "Extracting MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg to /usr/local/lib/python3.10/dist-packages\n",
            "Adding MultiScaleDeformableAttention 1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "Processing dependencies for MultiScaleDeformableAttention==1.0\n",
            "Finished processing dependencies for MultiScaleDeformableAttention==1.0\n"
          ]
        }
      ],
      "source": [
        "!cd /content/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification/Deformable-DETR/models/ops && python setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7e8PlD6urbL",
        "outputId": "a0d2913c-1738-41a8-b6e5-d7d3f5f80301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V16XL69ApGnO",
        "outputId": "f786eeb4-b76b-49bb-c51e-b3ca8b7cb69b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Adapter', 'ConvBNReLU', 'DropPath', 'ECALayer', 'ECB', 'E_MHSA', 'F', 'LTB', 'LocalityFeedForward', 'MHCA', 'MedViT', 'MedViT_base', 'MedViT_large', 'MedViT_small', 'Mlp', 'NORM_EPS', 'PatchEmbed', 'SELayer', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_make_divisible', 'checkpoint', 'h_sigmoid', 'h_swish', 'math', 'merge_pre_bn', 'nn', 'normal_', 'partial', 'rearrange', 'register_model', 'torch', 'trunc_normal_']\n"
          ]
        }
      ],
      "source": [
        "import MedVit\n",
        "print(dir(MedVit))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymU2ZgNkr2LC",
        "outputId": "ccd04e82-d937-4388-e145-7f32f0494371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting medmnist\n",
            "  Downloading medmnist-2.2.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.19.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.65.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (8.4.0)\n",
            "Collecting fire (from medmnist)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.15.2+cu118)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2022.7.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2023.7.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (23.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->medmnist) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->medmnist) (16.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->medmnist) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->medmnist) (1.3.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116932 sha256=9f1fd24d0c2a7421667f423564ffa8542ad449355566373457efb75ce88b8059\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, medmnist\n",
            "Successfully installed fire-0.5.0 medmnist-2.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install medmnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_7efN9KhHS15"
      },
      "outputs": [],
      "source": [
        "import medmnist\n",
        "from medmnist import INFO\n",
        "data_flag = 'retinamnist'\n",
        "# [tissuemnist , pathmnist, chestmnist, dermamnist, octmnisr]\n",
        "# ,pnemonismnist , retinamnist, bloodmnist, tissuemnist, organcmist, organs ]\n",
        "download = True\n",
        "\n",
        "NUM_EPOCHS = 15\n",
        "BATCH_SIZE = 15\n",
        "LR = 0.005\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oC-P48ynHS49"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "#preprocessing\n",
        "train_transform = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.Lambda(lambda image:image.convert('RGB')),\n",
        "        transforms.AugMix(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "]\n",
        ")\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image:image.convert('RGB')),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKvLoUSsHS7r",
        "outputId": "d6c36687-9fc6-4b87-ee5a-cbcbe8256f15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://zenodo.org/record/6496656/files/retinamnist.npz?download=1 to /root/.medmnist/retinamnist.npz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3291041/3291041 [00:00<00:00, 26294575.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/retinamnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/retinamnist.npz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch.utils.data as data\n",
        "#load the data\n",
        "train_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
        "val_dataset = DataClass(split='val', transform=train_transform, download=download)\n",
        "test_dataset = DataClass(split='test', transform=test_transform, download=download)\n",
        "\n",
        "#encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_loader_at_eval = data.DataLoader(dataset=val_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c93vOY4ANhzB",
        "outputId": "a005223f-21f6-4cc1-c016-178f3514638a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset RetinaMNIST (retinamnist)\n",
            "    Number of datapoints: 1080\n",
            "    Root location: /root/.medmnist\n",
            "    Split: train\n",
            "    Task: ordinal-regression\n",
            "    Number of channels: 3\n",
            "    Meaning of labels: {'0': '0', '1': '1', '2': '2', '3': '3', '4': '4'}\n",
            "    Number of samples: {'train': 1080, 'val': 120, 'test': 400}\n",
            "    Description: The RetinaMNIST is based on the DeepDRiD challenge, which provides a dataset of 1,600 retina fundus images. The task is ordinal regression for 5-level grading of diabetic retinopathy severity. We split the source training set with a ratio of 9:1 into training and validation set, and use the source validation set as the test set. The source images of 3×1,736×1,824 are center-cropped and resized into 3×28×28.\n",
            "    License: CC BY 4.0\n",
            "+++++++++++++++++\n",
            "Dataset RetinaMNIST (retinamnist)\n",
            "    Number of datapoints: 400\n",
            "    Root location: /root/.medmnist\n",
            "    Split: test\n",
            "    Task: ordinal-regression\n",
            "    Number of channels: 3\n",
            "    Meaning of labels: {'0': '0', '1': '1', '2': '2', '3': '3', '4': '4'}\n",
            "    Number of samples: {'train': 1080, 'val': 120, 'test': 400}\n",
            "    Description: The RetinaMNIST is based on the DeepDRiD challenge, which provides a dataset of 1,600 retina fundus images. The task is ordinal regression for 5-level grading of diabetic retinopathy severity. We split the source training set with a ratio of 9:1 into training and validation set, and use the source validation set as the test set. The source images of 3×1,736×1,824 are center-cropped and resized into 3×28×28.\n",
            "    License: CC BY 4.0\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset)\n",
        "print(\"+++++++++++++++++\")\n",
        "print(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZq_g3FfNi1a",
        "outputId": "2f8bd5f4-8439-4450-a0e7-a12f6a3db8d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initialize_weights...\n"
          ]
        }
      ],
      "source": [
        "from MedVit import MedViT_small as small\n",
        "model = small()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tavZqnG-N27T"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "model.proj_head[0] = nn.Linear(in_features=1024, out_features=n_classes, bias=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7o-_mX4hN3GD"
      },
      "outputs": [],
      "source": [
        "#Define loss function and optimizer\n",
        "if task == \"multi-task, binary-class\":\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "else:\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiPH8w-OOYmq",
        "outputId": "fe88c7a3-7af7-4563-f103-343713058d95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "criterion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ERg9aYl8Ob0w"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK5wgbNZOb3m",
        "outputId": "137bdaed-820e-48c9-9382-9290e1ee56c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72/72 [00:40<00:00,  1.78it/s]\n",
            "100%|██████████| 72/72 [00:33<00:00,  2.17it/s]\n",
            "100%|██████████| 72/72 [00:33<00:00,  2.15it/s]\n",
            "100%|██████████| 72/72 [00:33<00:00,  2.13it/s]\n",
            "100%|██████████| 72/72 [00:33<00:00,  2.13it/s]\n",
            "100%|██████████| 72/72 [00:33<00:00,  2.15it/s]\n",
            "100%|██████████| 72/72 [00:34<00:00,  2.11it/s]\n",
            "100%|██████████| 72/72 [00:33<00:00,  2.12it/s]\n",
            "100%|██████████| 72/72 [00:33<00:00,  2.14it/s]\n",
            "100%|██████████| 72/72 [00:34<00:00,  2.11it/s]\n",
            "100%|██████████| 72/72 [00:33<00:00,  2.13it/s]\n",
            "100%|██████████| 72/72 [00:33<00:00,  2.14it/s]\n",
            "100%|██████████| 72/72 [00:33<00:00,  2.13it/s]\n",
            "100%|██████████| 72/72 [00:33<00:00,  2.14it/s]\n",
            "100%|██████████| 72/72 [00:33<00:00,  2.13it/s]\n"
          ]
        }
      ],
      "source": [
        "from torch.nn.functional import softmax\n",
        "from tqdm import tqdm\n",
        "#training\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  model = model.to(device)\n",
        "  model.train()\n",
        "  for inputs, targets in tqdm(train_loader):\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs.to(torch.float32))\n",
        "    if task == \"multi-label, binary-class\":\n",
        "      targets = targets.to(torch.float32).unsqueeze(1)\n",
        "    else:\n",
        "      targets = targets.to(torch.long)\n",
        "      targets = targets.view(-1)\n",
        "\n",
        "    predicted_classes = torch.argmax(outputs, dim=1)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Delete tensors to free u.ep memory\n",
        "    del inputs, targets, outputs, predicted_classes\n",
        "    # Empty the cache to clear up some memory\n",
        "    torch.cuda.empty_cache\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2ECDjT1Ob61",
        "outputId": "4361e49c-c95a-4220-a14b-be0b7620dc85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Evaluating...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:02<00:00,  1.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "actuals: [0, 2, 0, 0, 0, 0, 1, 2, 0, 3, 2, 0, 0, 0, 0, 0, 3, 2, 1, 3, 0, 1, 0, 2, 0, 0, 1, 0, 0, 3, 3, 3, 4, 0, 0, 3, 3, 1, 0, 0, 0, 0, 0, 0, 1, 1, 2, 3, 2, 4, 0, 0, 0, 3, 2, 0, 4, 3, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 1, 3, 2, 3, 0, 3, 0, 0, 0, 2, 1, 2, 2, 0, 2, 2, 0, 2, 2, 2, 3, 4, 0, 1, 0, 2, 4, 0, 2, 0, 0, 3, 4, 3, 2, 1, 2, 0, 2, 0, 2, 2, 0, 3, 1, 0, 3, 3, 0, 0, 0]\n",
            "predictions: [3, 3, 0, 2, 3, 0, 3, 3, 3, 3, 3, 0, 0, 3, 3, 0, 3, 3, 1, 3, 0, 3, 0, 3, 0, 0, 3, 0, 0, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0, 3, 3, 1, 3, 1, 2, 1, 0, 0, 0, 3, 3, 0, 3, 3, 3, 3, 3, 0, 3, 3, 0, 1, 1, 3, 0, 3, 3, 3, 3, 0, 3, 0, 3, 0, 1, 3, 3, 3, 0, 3, 2, 0, 3, 1, 3, 3, 3, 3, 1, 0, 3, 3, 0, 3, 1, 3, 3, 3, 3, 1, 3, 3, 0, 3, 0, 3, 0, 0, 3, 3, 3, 3, 3, 0, 0, 3]\n",
            "AUC of the model: 0.8153121639554897\n",
            "Accuracy of the model: 0.49166666666666664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:04<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "actuals: [2, 1, 0, 0, 0, 0, 2, 2, 0, 3, 2, 2, 0, 3, 0, 0, 0, 2, 4, 0, 0, 0, 0, 0, 2, 0, 0, 3, 0, 3, 0, 0, 3, 1, 0, 0, 0, 3, 1, 0, 1, 0, 0, 0, 3, 3, 1, 1, 1, 0, 0, 3, 3, 0, 1, 1, 2, 0, 0, 1, 0, 0, 4, 0, 2, 2, 0, 1, 0, 3, 0, 1, 0, 2, 3, 1, 4, 3, 0, 0, 2, 0, 0, 4, 3, 0, 0, 1, 3, 0, 2, 1, 0, 2, 3, 4, 2, 1, 0, 0, 0, 3, 0, 0, 0, 4, 0, 0, 3, 0, 2, 2, 0, 2, 0, 0, 2, 1, 3, 2, 3, 2, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 2, 0, 1, 0, 1, 2, 2, 1, 1, 0, 1, 0, 3, 0, 2, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 4, 3, 2, 3, 1, 0, 0, 2, 2, 0, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 3, 3, 2, 0, 2, 3, 1, 3, 0, 2, 4, 2, 3, 0, 1, 4, 0, 3, 0, 2, 2, 1, 0, 2, 0, 0, 2, 2, 0, 0, 1, 0, 2, 2, 2, 0, 3, 2, 1, 2, 0, 2, 0, 3, 0, 0, 2, 0, 0, 0, 1, 2, 0, 4, 3, 1, 2, 0, 0, 0, 1, 0, 2, 3, 3, 2, 1, 2, 2, 0, 0, 4, 0, 0, 2, 4, 3, 4, 3, 3, 2, 0, 0, 0, 1, 0, 3, 0, 3, 0, 1, 1, 0, 0, 4, 0, 2, 3, 0, 2, 2, 2, 1, 3, 3, 0, 3, 2, 1, 0, 0, 2, 3, 0, 2, 0, 3, 3, 3, 0, 1, 0, 3, 0, 0, 0, 0, 0, 2, 3, 3, 1, 2, 3, 0, 2, 2, 3, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 1, 0, 2, 2, 2, 1, 0, 3, 3, 3, 3, 0, 0, 2, 0, 2, 0, 2, 3, 0, 0, 4, 3, 1, 3, 0, 0, 3, 4, 4, 2, 1, 3, 2, 0, 0, 0, 0, 0, 2, 3, 0, 3, 3, 0, 2, 4, 1, 0, 0, 2, 0, 0, 2, 0, 3, 0, 0, 0, 0, 4, 2, 2, 0, 2, 0, 4]\n",
            "predictions: [0, 1, 0, 3, 0, 0, 3, 3, 0, 3, 0, 3, 3, 3, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 3, 3, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 0, 3, 1, 3, 0, 0, 1, 3, 0, 3, 0, 0, 1, 0, 3, 1, 3, 0, 0, 0, 3, 3, 0, 0, 3, 0, 0, 3, 1, 0, 0, 3, 3, 0, 1, 3, 0, 1, 3, 0, 3, 1, 3, 3, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 3, 1, 3, 0, 3, 3, 0, 0, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 0, 1, 0, 0, 1, 3, 3, 3, 0, 3, 0, 3, 0, 3, 3, 1, 0, 3, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 2, 0, 3, 1, 0, 3, 0, 3, 1, 0, 0, 3, 0, 0, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 1, 2, 3, 3, 3, 3, 3, 0, 3, 0, 3, 3, 3, 3, 3, 2, 0, 3, 3, 0, 0, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 3, 0, 0, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 0, 0, 0, 3, 0, 3, 3, 3, 1, 0, 3, 1, 0, 0, 3, 0, 0, 3, 3, 3, 3, 3, 1, 3, 0, 0, 0, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 1, 3, 3, 1, 0, 3, 3, 3, 0, 3, 0, 3, 3, 3, 3, 3, 0, 3, 3, 0, 0, 0, 0, 1, 3, 3, 3, 0, 3, 0, 1, 0, 3, 3, 1, 3, 0, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 3, 1, 0, 0, 3, 0, 0, 0, 3, 3, 3, 3, 0, 3, 3, 2, 3, 0, 1, 3, 3, 3, 0, 3, 0, 0, 0, 3, 0, 3, 3, 0, 1, 3, 0, 0, 0, 3, 3, 0, 0, 0, 3, 0, 0, 3, 3, 1, 3, 2, 3, 3, 0, 3]\n",
            "AUC of the model: 0.7202257407146296\n",
            "Accuracy of the model: 0.505\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "# switch to evaluation mode\n",
        "def test(split):\n",
        "  model.eval()\n",
        "  # Lists to store actual and predicted values\n",
        "  actuals = []\n",
        "  probas = []\n",
        "  predictions = []\n",
        "\n",
        "  if split == 'val':\n",
        "        data_loader = train_loader_at_eval\n",
        "  else:\n",
        "        data_loader = test_loader\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for inputs, targets in tqdm(data_loader):\n",
        "\n",
        "          inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "          if task == 'multi-label, binary-class':\n",
        "              targets = targets.to(torch.float32).unsqueeze(1)\n",
        "          else:\n",
        "              targets = targets.to(torch.long)\n",
        "              targets = targets.view(-1)\n",
        "\n",
        "          outputs = model(inputs.to(torch.float32))\n",
        "          softmax_outputs = softmax(outputs, dim=1)\n",
        "\n",
        "          _, predicted_classes = torch.max(outputs, 1)\n",
        "\n",
        "          # Store the actual targets and predicted probabilities\n",
        "          actuals.extend(targets.cpu().numpy())\n",
        "          probas.extend(softmax_outputs.detach().cpu().numpy())\n",
        "          # Probability of positive class\n",
        "          predictions.extend(predicted_classes.cpu().numpy())\n",
        "  print('\\n')\n",
        "  auc = roc_auc_score(actuals, probas, multi_class='ovr')\n",
        "  accuracy = accuracy_score(actuals, predictions)\n",
        "  print(\"actuals:\",actuals)\n",
        "  print(\"predictions:\",predictions)\n",
        "  print('AUC of the model:', auc)\n",
        "  print('Accuracy of the model:', accuracy)\n",
        "\n",
        "print('==> Evaluating...')\n",
        "test('val')\n",
        "test('test')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
