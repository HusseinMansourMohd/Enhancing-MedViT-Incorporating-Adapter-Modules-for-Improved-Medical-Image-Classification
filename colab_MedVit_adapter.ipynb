{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/HusseinMansourMohd/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.utils\n",
    "import torchvision.datasets as dsets\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm\n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /content/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MedVit_adapter\n",
    "print(dir(MedVit_adapter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MedVit_adapter import MedViT_adapter_small as small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install medmnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO \n",
    "data_flag = 'retinamnist'\n",
    "# [tissuemnist , pathmnist, chestmnist, dermamnist, octmnisr]\n",
    "# ,pnemonismnist , retinamnist, bloodmnist, tissuemnist, organcmist, organs ]\n",
    "download = True\n",
    "\n",
    "NUM_EPOCHS = 15\n",
    "BATCH_SIZE = 15\n",
    "LR = 0.005\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "#preprocessing\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.Lambda(lambda image:image.convert('RGB')),\n",
    "    torchvision.transforms.AugMix(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "]\n",
    ")\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5],std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "# load the data\n",
    "train_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
    "val_dataset = DataClass(split='val', transform=train_transform,download=download)\n",
    "test_dataset = DataClass(split='test', transform=test_transform, download=download)\n",
    "\n",
    "\n",
    "# encapsulate data into dataloader form\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_loader_at_eval = data.DataLoader(dataset=val_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset)\n",
    "print(\"+++++++++++++++++\")\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = small()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.proj_head[0] = nn.Linear(in_features=1024, out_features=n_classes, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define loss function and optimizer\n",
    "if task == \"multi-task, binary-class\":\n",
    "  criterion = nn.BCEWithLogitsLoss()\n",
    "else:\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "from tqdm import tqdm\n",
    "# training\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "  model = model.to(device)\n",
    "  model.train()\n",
    "\n",
    "  for inputs, targets in tqdm(train_loader):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs.to(torch.float32))\n",
    "\n",
    "    if task == 'multi-label, binary-class':\n",
    "      targets = targets.to(torch.float32).unsqueeze(1)\n",
    "    else:\n",
    "      targets = targets.to(torch.long)\n",
    "      targets = targets.view(-1)\n",
    "\n",
    "\n",
    "    predicted_classes = torch.argmax(outputs, dim=1)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Delete tensors to free up memory\n",
    "    del inputs, targets, outputs, predicted_classes\n",
    "    # Empty the cache to clear up some more memory\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# switch to evaluation mode\n",
    "def test(split):\n",
    "  model.eval()\n",
    "  # Lists to store actual and predicted values\n",
    "  actuals = []\n",
    "  probas = []\n",
    "  predictions = []\n",
    "\n",
    "  if split == 'val':\n",
    "        data_loader = train_loader_at_eval\n",
    "  else:\n",
    "        data_loader = test_loader\n",
    "        \n",
    "  with torch.no_grad():\n",
    "      for inputs, targets in tqdm(data_loader):\n",
    "\n",
    "          inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "          if task == 'multi-label, binary-class':\n",
    "              targets = targets.to(torch.float32).unsqueeze(1)\n",
    "          else:\n",
    "              targets = targets.to(torch.long)\n",
    "              targets = targets.view(-1)\n",
    "\n",
    "          outputs = model(inputs.to(torch.float32))\n",
    "          softmax_outputs = softmax(outputs, dim=1)\n",
    "\n",
    "          _, predicted_classes = torch.max(outputs, 1)\n",
    "\n",
    "          # Store the actual targets and predicted probabilities\n",
    "          actuals.extend(targets.cpu().numpy())\n",
    "          probas.extend(softmax_outputs.detach().cpu().numpy())\n",
    "          # Probability of positive class\n",
    "          predictions.extend(predicted_classes.cpu().numpy())\n",
    "  print('\\n')\n",
    "  auc = roc_auc_score(actuals, probas, multi_class='ovr')\n",
    "  accuracy = accuracy_score(actuals, predictions)\n",
    "\n",
    "  print('AUC of the model:', auc)\n",
    "  print('Accuracy of the model:', accuracy)\n",
    "\n",
    "print('==> Evaluating...')\n",
    "test('val')\n",
    "test('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
