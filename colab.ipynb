{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 13 21:58:43 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 531.14                 Driver Version: 531.14       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 T...  WDDM | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   48C    P8               10W /  N/A|    159MiB /  4096MiB |     30%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      7284    C+G   ... Access Service\\ePowerButton_NB.exe    N/A      |\n",
      "|    0   N/A  N/A     17612    C+G   ...aming\\Telegram Desktop\\Telegram.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:/Users/hussein/Adapter_for_small_medical_datasets_classification/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification-1/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification/.git: Filename too long\n",
      "Cloning into 'Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/HusseinMansourMohd/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', 'colab.ipynb', 'MedVit_adapter.ipynb', 'MedVit_adapter.py', 'README.md', 'utils.py']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'summary' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pip install summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchsummary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hussein\\Adapter_for_small_medical_datasets_classification\\Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification-1\\colab.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hussein/Adapter_for_small_medical_datasets_classification/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification-1/colab.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hussein/Adapter_for_small_medical_datasets_classification/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification-1/colab.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mdsets\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hussein/Adapter_for_small_medical_datasets_classification/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification-1/colab.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchsummary\u001b[39;00m \u001b[39mimport\u001b[39;00m summary\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchsummary'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.utils\n",
    "from torchvision import models\n",
    "import torchvision.datasets as dsets\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm\n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', 'colab.ipynb', 'MedVit_adapter.ipynb', 'MedVit_adapter.py', 'README.md', 'utils.py']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'einops'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hussein\\Adapter_for_small_medical_datasets_classification\\Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification-1\\colab.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hussein/Adapter_for_small_medical_datasets_classification/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification-1/colab.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mMedVit_adapter\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hussein/Adapter_for_small_medical_datasets_classification/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification-1/colab.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mdir\u001b[39m(MedVit_adapter))\n",
      "File \u001b[1;32mc:\\Users\\hussein\\Adapter_for_small_medical_datasets_classification\\Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification-1\\MedVit_adapter.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcheckpoint\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mcheckpoint\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39meinops\u001b[39;00m \u001b[39mimport\u001b[39;00m rearrange\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtimm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m DropPath, trunc_normal_\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtimm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mregistry\u001b[39;00m \u001b[39mimport\u001b[39;00m register_model\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'einops'"
     ]
    }
   ],
   "source": [
    "import MedVit_adapter\n",
    "print(dir(MedVit_adapter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'einops'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hussein\\Adapter_for_small_medical_datasets_classification\\Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification-1\\colab.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hussein/Adapter_for_small_medical_datasets_classification/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification-1/colab.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mMedVit_adapter\u001b[39;00m \u001b[39mimport\u001b[39;00m MedViT_small \u001b[39mas\u001b[39;00m small\n",
      "File \u001b[1;32mc:\\Users\\hussein\\Adapter_for_small_medical_datasets_classification\\Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification-1\\MedVit_adapter.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcheckpoint\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mcheckpoint\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39meinops\u001b[39;00m \u001b[39mimport\u001b[39;00m rearrange\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtimm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m DropPath, trunc_normal_\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtimm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mregistry\u001b[39;00m \u001b[39mimport\u001b[39;00m register_model\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'einops'"
     ]
    }
   ],
   "source": [
    "from MedVit_adapter import MedViT_small as small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'small' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hussein\\Adapter_for_small_medical_datasets_classification\\Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification-1\\colab.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hussein/Adapter_for_small_medical_datasets_classification/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification-1/colab.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m small()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'small' is not defined"
     ]
    }
   ],
   "source": [
    "model = small()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hussein\\Adapter_for_small_medical_datasets_classification\\Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification-1\\colab.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hussein/Adapter_for_small_medical_datasets_classification/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification-1/colab.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mproj_head[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.proj_head[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hussein\\Adapter_for_small_medical_datasets_classification\\Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification-1\\colab.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hussein/Adapter_for_small_medical_datasets_classification/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification-1/colab.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mproj_head[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mLinear(in_features\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m, out_features\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, bias \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.proj_head[0] = torch.nn.Linear(in_features=1024, out_features=1, bias = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: medmnist in c:\\users\\hussein\\anaconda3\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from medmnist) (1.4.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from medmnist) (4.64.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from medmnist) (9.0.1)\n",
      "Requirement already satisfied: fire in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from medmnist) (0.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from medmnist) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from medmnist) (1.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from medmnist) (0.19.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from medmnist) (0.15.1)\n",
      "Requirement already satisfied: torch in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from medmnist) (2.0.0)\n",
      "Requirement already satisfied: six in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from fire->medmnist) (1.16.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from fire->medmnist) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from pandas->medmnist) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from pandas->medmnist) (2021.3)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from scikit-image->medmnist) (2.7.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from scikit-image->medmnist) (2.9.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from scikit-image->medmnist) (1.3.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from scikit-image->medmnist) (2021.7.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from scikit-image->medmnist) (1.7.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from scikit-image->medmnist) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from packaging>=20.0->scikit-image->medmnist) (3.0.4)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from scikit-learn->medmnist) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from scikit-learn->medmnist) (2.2.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from torch->medmnist) (1.10.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from torch->medmnist) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from torch->medmnist) (4.1.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from torch->medmnist) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from jinja2->torch->medmnist) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from sympy->torch->medmnist) (1.2.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from torchvision->medmnist) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from requests->torchvision->medmnist) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from requests->torchvision->medmnist) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from requests->torchvision->medmnist) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from requests->torchvision->medmnist) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hussein\\anaconda3\\lib\\site-packages (from tqdm->medmnist) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install medmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flag = 'breastmnist'\n",
    "# [tissuemnist , pathmnist, chestmnist, dermamnist, octmnisr]\n",
    "# ,pnemonismnist , retinamnist, bloodmnist, tissuemnist, organcmist, organs ]\n",
    "\n",
    "download = True\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 10\n",
    "LR = 0.005\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(medmnist,info['python_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.transforms import Resize\n",
    "#preprocessing\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
    "    torchvision.transforms.AugMix(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "test_transform =  transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "# load the data\n",
    "train_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
    "test_dataset = DataClass(split='test', transform=test_transform, download=download)\n",
    "\n",
    "\n",
    "# encapsulate data into dataloader form\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset)\n",
    "print(\"==============\")\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defune loss function and optimizer\n",
    "# define loss function and optimizer\n",
    "lr = 0.001\n",
    "if task == \"binary-class\":\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available, else use CPU\n",
    "model = model.to(device)  # Move model to the specified device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    print('Epoch [%d%d]'%(epoch+1, NUM_EPOCHS))\n",
    "    model.train()\n",
    "    for inputs, targets in tqdm(train_loader):\n",
    "        inputs, targets = inputs.cuda() , targets.cuda()\n",
    "        #forward + backward + optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        if task == 'multi-label, binary-class':\n",
    "            targets = targets.to(torch.floar32)\n",
    "            loss = criterion(outputs, targets)\n",
    "        else:\n",
    "            targets = targets.to(torch.float32)\n",
    "            loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "def test(split):\n",
    "    model.eval()\n",
    "    y_true = torch.tensor([]).cuda()\n",
    "    y_score = torch.tensor([]).cuda()\n",
    "\n",
    "    data_loader = train_loader_at_eval if split =='train' else test_loader\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs = model(inputs)  # here is where the model should produce outputs\n",
    "\n",
    "            if task == 'multi-task, binary-class':\n",
    "                targets = targets.to(torch.float32)\n",
    "                loss = criterion(outputs, targets)\n",
    "                print('loss=',loss)\n",
    "            else:\n",
    "                targets = targets.to(torch.long)  # targets for classification tasks are long integers\n",
    "                targets = targets.float()\n",
    "                #outputs = outputs.softmax(dim=1)\n",
    "                #print(outputs)\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                #print('loss=',loss)\n",
    "\n",
    "            y_true = torch.cat((y_true, targets), 0)\n",
    "            y_score = torch.cat((y_score, outputs.softmax(dim=0)), 0)  # apply softmax here for evaluation\n",
    "            print(y_score)\n",
    "        y_true = y_true.cpu().numpy()\n",
    "        \n",
    "        \n",
    "        y_score = y_score.detach().cpu().numpy()\n",
    "\n",
    "        y_pred = (y_score > 0.5).astype(int)\n",
    "\n",
    "        print(\"y_score.shape:\",y_score.flatten().shape)\n",
    "        print(\"y_true.shape:\",y_true.flatten().shape)\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        print(acc)\n",
    "        print(y_true[1:10])\n",
    "        print(y_score[1:10])\n",
    "        auc = roc_auc_score(y_true, y_score, multi_class='ovr')\n",
    "        #evaluator = Evaluator(data_flag, split)\n",
    "        #metrics = evaluator.evaluate(y_score)\n",
    "\n",
    "\n",
    "        print('%s auc: %.3f acc: %.3f' % (split,[acc, auc]))\n",
    "\n",
    "print('==> Evaluating...')\n",
    "test('train')\n",
    "test('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
