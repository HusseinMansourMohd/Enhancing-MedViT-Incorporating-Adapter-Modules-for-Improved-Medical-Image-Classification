{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8Q0gDnd3obC",
        "outputId": "d55ba3a4-3556-4888-92b0-61dcf0c44f0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jul 16 03:03:13 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   78C    P0    32W /  70W |   2603MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/HusseinMansourMohd/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daxgYR2B3tI2",
        "outputId": "71f07b3a-713e-49a3-aa68-d30a1926c8e9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification'...\n",
            "remote: Enumerating objects: 134, done.\u001b[K\n",
            "remote: Counting objects: 100% (134/134), done.\u001b[K\n",
            "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
            "remote: Total 134 (delta 64), reused 84 (delta 30), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (134/134), 43.69 KiB | 1.82 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcQCvSak3tLf",
        "outputId": "9fe4cb80-aa2d-4ce1-9456-5ab8e01159cd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['MedVit_adapter.ipynb', 'MedVit_adapter.py', 'utils.py', '.git', 'Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification', '__pycache__', 'README.md']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.utils\n",
        "import torchvision.datasets as dsets\n",
        "from torchsummary import summary\n"
      ],
      "metadata": {
        "id": "HoZTvcs-3tOe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtLfiqFp3tRU",
        "outputId": "a1a7de7f-2136-4911-cc4f-db78ef0ff913"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UJmGvL_5uaW",
        "outputId": "8a730ed4-7415-496c-fcc0-6ecbd5eac60f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Enhancing-MedViT-Incorporating-Adapter-Modules-for-Improved-Medical-Image-Classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(os.listdir())\n",
        "import MedVit_adapter\n",
        "print(dir(MedVit_adapter))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PptABl25udP",
        "outputId": "e3e62a66-6f16-4bab-d164-ffd84d32002a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Adapter', 'ConvBNReLU', 'DropPath', 'ECALayer', 'ECB', 'E_MHSA', 'F', 'LTB', 'LocalityFeedForward', 'MHCA', 'MedViT', 'MedViT_base', 'MedViT_large', 'MedViT_small', 'Mlp', 'NORM_EPS', 'PatchEmbed', 'SELayer', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_make_divisible', 'checkpoint', 'h_sigmoid', 'h_swish', 'math', 'merge_pre_bn', 'nn', 'partial', 'rearrange', 'register_model', 'torch', 'trunc_normal_']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from MedVit_adapter import MedViT_small as small"
      ],
      "metadata": {
        "id": "XTSVpU9Y5uh8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medmnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwZ7ZzKT-IxQ",
        "outputId": "220b7c69-9740-45ed-9e27-819073f4f25a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: medmnist in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.19.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.65.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (8.4.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.5.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.15.2+cu118)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2022.7.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2023.7.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (23.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->medmnist) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->medmnist) (16.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->medmnist) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->medmnist) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import medmnist\n",
        "from medmnist import INFO , Evaluator\n",
        "data_flag = 'retinamnist'\n",
        "# [tissuemnist , pathmnist, chestmnist, dermamnist, octmnisr]\n",
        "# ,pnemonismnist , retinamnist, bloodmnist, tissuemnist, organcmist, organs ]\n",
        "download = True\n",
        "\n",
        "NUM_EPOCHS = 15\n",
        "BATCH_SIZE = 15\n",
        "LR = 0.005\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])"
      ],
      "metadata": {
        "id": "iYys_Eix8CaF"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "import torchvision.transforms as transforms\n",
        "#preprocessing\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image:image.convert('RGB')),\n",
        "    torchvision.transforms.AugMix(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "]\n",
        ")\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5],std=[0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "2cXjGZNY9sWo"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
        "val_dataset = DataClass(split='val', transform=train_transform,download=download)\n",
        "test_dataset = DataClass(split='test', transform=test_transform, download=download)\n",
        "\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_loader_at_eval = data.DataLoader(dataset=val_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeeLhtkF8CdQ",
        "outputId": "d8d1f4d4-ac64-41b8-9b9f-fa460001eb36"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/retinamnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/retinamnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/retinamnist.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset)\n",
        "print(\"+++++++++++++++++\")\n",
        "print(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAYA7zLlMzF2",
        "outputId": "30a4476e-b211-49c6-88c0-9e8099502e55"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset RetinaMNIST (retinamnist)\n",
            "    Number of datapoints: 1080\n",
            "    Root location: /root/.medmnist\n",
            "    Split: train\n",
            "    Task: ordinal-regression\n",
            "    Number of channels: 3\n",
            "    Meaning of labels: {'0': '0', '1': '1', '2': '2', '3': '3', '4': '4'}\n",
            "    Number of samples: {'train': 1080, 'val': 120, 'test': 400}\n",
            "    Description: The RetinaMNIST is based on the DeepDRiD challenge, which provides a dataset of 1,600 retina fundus images. The task is ordinal regression for 5-level grading of diabetic retinopathy severity. We split the source training set with a ratio of 9:1 into training and validation set, and use the source validation set as the test set. The source images of 3×1,736×1,824 are center-cropped and resized into 3×28×28.\n",
            "    License: CC BY 4.0\n",
            "+++++++++++++++++\n",
            "Dataset RetinaMNIST (retinamnist)\n",
            "    Number of datapoints: 400\n",
            "    Root location: /root/.medmnist\n",
            "    Split: test\n",
            "    Task: ordinal-regression\n",
            "    Number of channels: 3\n",
            "    Meaning of labels: {'0': '0', '1': '1', '2': '2', '3': '3', '4': '4'}\n",
            "    Number of samples: {'train': 1080, 'val': 120, 'test': 400}\n",
            "    Description: The RetinaMNIST is based on the DeepDRiD challenge, which provides a dataset of 1,600 retina fundus images. The task is ordinal regression for 5-level grading of diabetic retinopathy severity. We split the source training set with a ratio of 9:1 into training and validation set, and use the source validation set as the test set. The source images of 3×1,736×1,824 are center-cropped and resized into 3×28×28.\n",
            "    License: CC BY 4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = small()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UlFxBlEN6uB",
        "outputId": "2589e260-eed1-4331-cec8-f7019b6de701"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.proj_head[0] = nn.Linear(in_features=1024, out_features=5, bias=True)"
      ],
      "metadata": {
        "id": "-wOFxIeCSzFP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define loss function and optimizer\n",
        "if task == \"multi-task, binary-class\":\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "else:\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)"
      ],
      "metadata": {
        "id": "emZ7A72KMzI4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgeQnT4VMzLj",
        "outputId": "2b7bd48a-b8e6-4b4a-d361-b86dc9a7c91a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-46sTFEQzr7",
        "outputId": "2e98531c-67e5-493c-a7ce-d5b4ccb300d1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7bb7192ed150>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "czPE7-0Y-AeD"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import softmax\n",
        "from tqdm import tqdm\n",
        "# training\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "  #print('Epoch [%d ,%d]'%(epoch+1, NUM_EPOCHS))\n",
        "  model = model.to(device)\n",
        "  model.train()\n",
        "\n",
        "  for inputs, targets in tqdm(train_loader):\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs.to(torch.float32))\n",
        "\n",
        "    if task == 'multi-label, binary-class':\n",
        "      targets = targets.to(torch.float32).unsqueeze(1)\n",
        "    else:\n",
        "      targets = targets.to(torch.long)\n",
        "      targets = targets.view(-1)\n",
        "\n",
        "\n",
        "    predicted_classes = torch.argmax(outputs, dim=1)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Delete tensors to free up memory\n",
        "    del inputs, targets, outputs, predicted_classes\n",
        "    # Empty the cache to clear up some more memory\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N97d9aUSOFCV",
        "outputId": "5c5f5646-d092-4a6d-c546-5c551d08219c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 4/72 [00:03<01:07,  1.01it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "# switch to evaluation mode\n",
        "def test(split):\n",
        "  model.eval()\n",
        "  # Lists to store actual and predicted values\n",
        "  actuals = []\n",
        "  probas = []\n",
        "  predictions = []\n",
        "\n",
        "#  data_loader = train_loader_at_eval if split =='train' else test_loader\n",
        "\n",
        "  if split == 'train':\n",
        "        data_loader = train_loader_at_eval\n",
        "        print('train_loader_at_eval')\n",
        "  else:\n",
        "        data_loader = test_loader\n",
        "        print('test_loader')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for inputs, targets in tqdm(test_loader):\n",
        "          inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "          if task == 'multi-label, binary-class':\n",
        "              targets = targets.to(torch.float32).unsqueeze(1)\n",
        "          else:\n",
        "              targets = targets.to(torch.long)\n",
        "              targets = targets.view(-1)\n",
        "\n",
        "          outputs = model(inputs.to(torch.float32))\n",
        "          softmax_outputs = softmax(outputs, dim=1)\n",
        "\n",
        "          _, predicted_classes = torch.max(outputs, 1)\n",
        "\n",
        "          # Store the actual targets and predicted probabilities\n",
        "          actuals.extend(targets.cpu().numpy())\n",
        "          probas.extend(softmax_outputs.detach().cpu().numpy())\n",
        "          # Probability of positive class\n",
        "          predictions.extend(predicted_classes.cpu().numpy())\n",
        "\n",
        "  auc = roc_auc_score(actuals, probas, multi_class='ovr')\n",
        "  accuracy = accuracy_score(actuals, predictions)\n",
        "  print('\\n AUC of the model on test data:', auc)\n",
        "  print('\\n Accuracy of the model on test data:', accuracy)\n",
        "\n",
        "print('==> Evaluating...')\n",
        "test('val')\n",
        "test('test')\n"
      ],
      "metadata": {
        "id": "NU9my-LT9I5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "def test(split):\n",
        "    model.eval()\n",
        "    y_true = torch.tensor([]).cuda()\n",
        "    y_score = torch.tensor([]).cuda()\n",
        "\n",
        "    data_loader = train_loader_at_eval if split =='train' else test_loader\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = model(inputs)  # here is where the model should produce outputs\n",
        "\n",
        "            if task == 'multi-task, binary-class':\n",
        "                targets = targets.to(torch.float32)\n",
        "                loss = criterion(outputs, targets)\n",
        "                print('loss=',loss)\n",
        "            else:\n",
        "                targets = targets.to(torch.long)  # targets for classification tasks are long integers\n",
        "                targets = targets.float()\n",
        "                #outputs = outputs.softmax(dim=1)\n",
        "                #print(outputs)\n",
        "\n",
        "                loss = criterion(outputs, targets)\n",
        "                #print('loss=',loss)\n",
        "\n",
        "            y_true = torch.cat((y_true, targets), 0)\n",
        "            y_score = torch.cat((y_score, outputs), 0)  # apply softmax here for evaluation\n",
        "\n",
        "        y_true = y_true.cpu().numpy()\n",
        "\n",
        "        y_score = y_score.detach().cpu().numpy()\n",
        "\n",
        "        y_pred = np.argmax(y_score, axis=1)\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "        print('y_pred:',y_pred)\n",
        "        print('y_true:',y_true)\n",
        "\n",
        "        #y_pred = (y_score > 0.5).astype(int)\n",
        "\n",
        "        #print(\"y_score.shape:\",y_score.flatten().shape)\n",
        "        #print(\"y_true.shape:\",y_true.flatten().shape)\n",
        "\n",
        "        acc = accuracy_score(y_true, y_score)\n",
        "        print(acc)\n",
        "        #print(y_true[1:10])\n",
        "        #print(y_score[1:10])\n",
        "        auc = roc_auc_score(y_true, y_score, multi_class='ovr')\n",
        "        #evaluator = Evaluator(data_flag, split)\n",
        "        #metrics = evaluator.evaluate(y_score)\n",
        "\n",
        "\n",
        "        print('%s auc: %.3f acc: %.3f' % (split,[acc, auc]))\n",
        "\n",
        "print('==> Evaluating...')\n",
        "test('train')\n",
        "test('test')"
      ],
      "metadata": {
        "id": "Z_mAaOs2HqZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_9mnsPlU9I9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jTDdfEuf9JC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s1Pke2gV9JGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "# from scipy.special import softmax\n",
        "\n",
        "# #Evaluation\n",
        "# def test(split):\n",
        "#   model.eval()\n",
        "#   y_true = torch.tensor([]).to(device)\n",
        "#   y_score = torch.tensor([]).to(device)\n",
        "\n",
        "#   data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
        "\n",
        "#   with torch.no_grad():\n",
        "#     for inputs, targets in data_loader:\n",
        "#       inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "#       outputs = model(inputs)\n",
        "\n",
        "#       if task == 'multi-task, binary-class':\n",
        "#         targets = targets.to(torch.float32)\n",
        "#       else:\n",
        "#         targets = targets.to(torch.long)\n",
        "\n",
        "#         loss = criterion(outputs, targets)\n",
        "\n",
        "#         y_true = torch.cat((y_true, targets), 0)\n",
        "#         y_score = torch.cat((y_score, outputs), 0)\n",
        "\n",
        "#       y_true = y_true.cpu().numpy()\n",
        "#       y_score = y_score.cpu().numpy()\n",
        "\n",
        "#       y_score_softmax = softmax(y_score, axis=1)\n",
        "#       y_pred = np.argmax(y_score_softmax, axis=1)\n",
        "\n",
        "#       acc = accuracy_score(y_true, y_pred)\n",
        "#       auc = roc_auc_score(y_true, y_score_softmax, multi_class='ovr')\n",
        "\n",
        "#       print(f'{split} auc:{auc:.3f}, acc:{acc:.3f}')\n",
        "\n",
        "# print('==> Evaluating..')\n",
        "# test('train')\n",
        "# test('test')"
      ],
      "metadata": {
        "id": "DTGXw_DwOFFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P2ZErpjZOFH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C8h1ICVqOFLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2X9tzAbiMzOn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}